# -*- coding: utf-8 -*-
"""CNN and Transfer Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Hj6d4a_XG2AC6gC6CxTBWLd0-CCT9U6N
"""

!pip install keras numpy matplotlib glob2

#Import the required packages/dependencies
from keras.layers import Lambda, Dense, Input, Dense, Flatten, Conv2D
from keras.models import Model, load_model
from keras.models import Sequential
from keras.applications.vgg19 import VGG19
from keras.applications.resnet50 import preprocess_input
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator, load_img
import numpy as np
from glob import glob
import matplotlib.pyplot as plt

#Load the data set and resize images
IMAGE_SIZE = [224, 224]
train_path  ="/content/drive/My Drive/Dataset/Train"
valid_path  ="/content/drive/My Drive/Dataset/Test"

vgg19 = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)

#vgg19.summary()

#don't train the existing weights
for layer in vgg19.layers:
  layer.trainable = False

#useful for getting number of output classes
folders =  glob("/content/drive/My Drive/Dataset/Train/*")
folders

#our layers
x = Flatten()(vgg19.output)

prediction = Dense(len(folders), activation='softmax')(x)

#Create a model object
model = Model(inputs=vgg19.input, outputs=prediction)

model.summary()

#telling the model what cost and optimization method to use
model.compile(
    loss = 'categorical_crossentropy',
    optimizer = 'adam',
    metrics = ['accuracy']
)

#using the ImageDataGenerator to import the images from the dataset
train_datagen = ImageDataGenerator(
    rescale = 1./225,
    shear_range = 0.2,
    zoom_range = 0.2,
    horizontal_flip = True
    )

test_datagen = ImageDataGenerator(rescale = 1./255)

training_set = train_datagen.flow_from_directory(train_path, 
                                                 target_size = (224, 224),
                                                 batch_size = 32,
                                                 class_mode = 'categorical'
                                                 )

training_set

test_set = test_datagen.flow_from_directory(valid_path,
                                            target_size = (224, 224),
                                            batch_size = 32,
                                            class_mode = 'categorical')

# fit the model
# Run the cell. It will take some time to execute
r = model.fit_generator(
  training_set,
  validation_data=test_set,
  epochs=10,
  steps_per_epoch=len(training_set),
  validation_steps=len(test_set)
)

# plotting the loss
plt.plot(r.history['loss'], label='train loss')
plt.plot(r.history['val_loss'], label='val loss')
plt.legend()
plt.show()
plt.savefig('LossVal_loss')

# plot the accuracy
plt.plot(r.history['accuracy'], label='train acc')
plt.plot(r.history['val_accuracy'], label='val acc')
plt.legend()
plt.show()
plt.savefig('AccVal_acc')

# save it as a h5 file
# model.save('model_vgg19.h5')
!mkdir -p saved_model
model.save('saved_model/model_vgg19.h5')

#Predicting the test dataset
y_pred = model.predict(test_set)
y_pred

y_pred = np.argmax(y_pred, axis=1)
y_pred

model=load_model('/content/saved_model/model_vgg19.h5')

#Loading a particular image from the test data set
img=image.load_img('/content/drive/My Drive/Dataset/Test/Uninfected/2.png',target_size=(224,224))

#COnvetting it into an array
x=image.img_to_array(img)
x

x.shape

x=x/255

x=np.expand_dims(x,axis=0)
img_data=preprocess_input(x)
img_data.shape

#Predicting the particular image
pred = model.predict(img_data)
pred

a=np.argmax(pred, axis=1)

if(a==1):
    print("Uninfected")
else:
    print("Infected")